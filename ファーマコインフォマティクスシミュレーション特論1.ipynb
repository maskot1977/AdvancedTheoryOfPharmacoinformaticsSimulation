{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maskot1977/AdvancedTheoryOfPharmacoinformaticsSimulation/blob/main/%E3%83%95%E3%82%A1%E3%83%BC%E3%83%9E%E3%82%B3%E3%82%A4%E3%83%B3%E3%83%95%E3%82%A9%E3%83%9E%E3%83%86%E3%82%A3%E3%82%AF%E3%82%B9%E3%82%B7%E3%83%9F%E3%83%A5%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E7%89%B9%E8%AB%961.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBa1OgNwG7-_"
      },
      "source": [
        "# ファーマコインフォマティクスシミュレーション特論\n",
        "\n",
        "　　　小寺 正明 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBbUUFADJh3O"
      },
      "source": [
        "# 第1回：過剰適合（過学習）\n",
        "\n",
        "過剰適合とは、ある特定の問題に過剰に適合した結果、汎化性能を失うことをさします。「過学習」という言葉の方が知名度が高いですが、誤解を招きやすい言葉だと個人的には思っていて、「過剰適合」という言葉の方が私は好きです。\n",
        "\n",
        "過剰適合の様子をPythonコードで実演してみましょう。まず、次のような関数を用意します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9Bgvf0Nfs5F"
      },
      "outputs": [],
      "source": [
        "# 関数 f(x) を定義します。\n",
        "import numpy as np\n",
        "\n",
        "f = lambda x: 0.05*x+0.8*np.sin(3/4 * x) # 講義中はこの関数を用います。\n",
        "#f = lambda x: 0.2*np.sin(x) + 0.3*np.cos(2*x) + 0.5*np.sin(2/3*x) + 0.2*np.sin(x/3) # 課題で用います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byKPeeZvgL0I"
      },
      "outputs": [],
      "source": [
        "# x の定義域を決めます。\n",
        "x_test = np.linspace(-10, 10, 101) # test data\n",
        "x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12FbzY12kEkq"
      },
      "outputs": [],
      "source": [
        "# 真の f(x) の値\n",
        "t_test = f(x_test)\n",
        "t_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkeGLDsxgRgS"
      },
      "outputs": [],
      "source": [
        "# 描画します。\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(x_test, t_test, label=\"true f(x) (test data)\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"t = f(x)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiTjUdag4H2f"
      },
      "source": [
        "何か注目している現象があるとして、その現象の「真の姿」は上記の関数に従うが、私たちはその関数を知らないものとします。何度か実験を行うことにより、いくつかの x に対してその t = f(x) の値は測定することができます。しかし、無限回数の実験を行うことはできませんし、測定値には常に誤差が伴います。そこで、<b>限られた回数の誤差を含む測定実験から、真の姿をどのくらい正しく予測できるか</b>をシミュレーションしてみたいと思います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySojDrWHWHv4"
      },
      "source": [
        "機械学習では、データを次のように分割することがあります（用いる用語は、人によって異なる場合があります）。\n",
        "\n",
        "- **training data（訓練データ、教師データ、学習データ）**\n",
        "    - 機械学習モデルを訓練するために用いるデータ。説明変数と目的変数の組から成る。\n",
        "- **validation data（検証データ）**\n",
        "    - 機械学習モデルの性能を評価するために用いるデータ。説明変数と目的変数の組から成る。\n",
        "- **test data（テストデータ）**\n",
        "    - 学習に用いず、実際に予測値を出したいデータ。目的変数は必ずしも明らかになっていない。\n",
        "\n",
        "ここでは、訓練データ、検証データ、テストデータの説明変数 $x$ を次のように決めます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjuGR-nwHYja"
      },
      "outputs": [],
      "source": [
        "x_train = np.linspace(-10, 10, 11) # training data\n",
        "x_valid = np.linspace(-9, 9, 10) # validation data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7z7G1NZWbmZ"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "ここで、訓練データや検証データに対応する目的変数 $y$ の値には、何らかの誤差が含まれているものとします。図示してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8ibFNP9HcZZ"
      },
      "outputs": [],
      "source": [
        "epsilon = 0.1 # 誤差の大きさを決める定数\n",
        "t_train = f(x_train) + epsilon * np.cos(1.9*x_train + 1.3) # 誤差の含まれた教師データ\n",
        "t_valid = f(x_valid) + epsilon * np.cos(1.7*x_valid + 1.1) # 誤差の含まれた検証データ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2U3AEoshPid"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_train, t_train, marker='o', label=\"training data\")\n",
        "plt.scatter(x_valid, t_valid, marker='x', label=\"validation data\")\n",
        "plt.plot(x_test, t_test, label=\"true f(x) (test data)\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EG7NR0bX7h3"
      },
      "source": [
        "ここで問題は、**訓練データだけから、検証データやテストデータを正しく予測できるか？** ということになります。\n",
        "\n",
        "機械学習手法はたくさんありますが、ここでは \n",
        "\n",
        "- Support Vector Machine (SVM)\n",
        "- K-Nearest Neighbors (KNN)\n",
        "- Random Forest\n",
        "- Gradient Boosting\n",
        "- Multi-layer Perceptron (MLP) \n",
        "\n",
        "を取扱います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axceMZfN5fR4"
      },
      "source": [
        "## SVM (SVR)\n",
        "\n",
        "どの機械学習モデルでも、「モデルの作成」「学習」「予測」「性能評価」という流れになります。\n",
        "\n",
        "ここでは、SVMがどのように予測問題を解くかの説明は省略します。使い方を理解することと、SVMによる予測がどのような「クセ」を持っているのかというイメージをつかんでいただけたらと思います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktla6CleiIJs"
      },
      "outputs": [],
      "source": [
        "# 機械学習モデルを作成する\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "params = {\"kernel\":\"rbf\", \"C\":1e64, \"gamma\":1e8}\n",
        "model = SVR(**params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1ajdsL1iqK9"
      },
      "outputs": [],
      "source": [
        "# 学習する\n",
        "model.fit(x_train.reshape(-1, 1), t_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjBVsz8bjYiV"
      },
      "outputs": [],
      "source": [
        "# 訓練データを予測\n",
        "y_train = model.predict(x_train.reshape(-1, 1))\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz1dStwFjcfU"
      },
      "outputs": [],
      "source": [
        "# 検証データを予測\n",
        "y_valid = model.predict(x_valid.reshape(-1, 1))\n",
        "y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHb3F1qpi6-D"
      },
      "outputs": [],
      "source": [
        "# テストデータを予測\n",
        "y_test = model.predict(x_test.reshape(-1, 1))\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moBQtyxxjqtO"
      },
      "outputs": [],
      "source": [
        "# 訓練データの予測性能の評価（平均絶対誤差）\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "mean_absolute_error(t_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzOCEIVAkhI4"
      },
      "outputs": [],
      "source": [
        "# 検証データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epp9q3iZklPH"
      },
      "outputs": [],
      "source": [
        "# テストデータの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb9yqn8d60Qu"
      },
      "source": [
        "以上の計算では、性能評価指標として「平均絶対誤差」を使いました（性能評価指標は他にもあります）。この数字が小さいほど、機械学習モデルの性能が優れているということになります。\n",
        "\n",
        "それでは、訓練データ、検証データ、テストデータで、どの指標が最も良いでしょうか？\n",
        "\n",
        "普通は、訓練データの指標が最も良くなります。訓練データを用いて訓練しているので、当たり前ですね。検証データやテストデータの指標が、たまたま、最も良くなることはありえますが、普通は訓練データの指標よりも悪い数字が出ます。\n",
        "\n",
        "数字だけでは、どのような予測結果になったのかイメージしにくいので、予測結果を図示してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AscLBpzkkvJn"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_train, t_train, marker='o', label=\"train\")\n",
        "plt.scatter(x_valid, t_valid, marker='x', label=\"valid\")\n",
        "plt.plot(x_test, t_test, label=\"test (true)\")\n",
        "plt.plot(x_test, y_test, label=\"test (predicted)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27NxgCh69iy8"
      },
      "source": [
        "これは良い予測結果と思えるでしょうか？\n",
        "\n",
        "思えませんよね。訓練データの指標が良くなるように無理矢理合わせているだけで、検証データやテストデータの予測性能は非常に悪いことが分かると思います。これが overfitting の例です。\n",
        "\n",
        "そして、無理矢理合わせるときに、こんな形をして合わせようとするのが SVM の「クセ」です。\n",
        "\n",
        "今回は、わざと、SVMのハイパーパラメーターとして無茶苦茶な値を設定しました。後に、ハイパーパラメーターを適切な値に設定する（チューニングする）方法を解説します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL5TQAdB-djc"
      },
      "source": [
        "# Random Forest\n",
        "\n",
        "ハイパーパラメーターのチューニングは後回しにして、今度は、SVM以外の他の機械学習モデルを使ってみることにしましょう。\n",
        "\n",
        "Random Forest を使ってみます。ここでも、Random Forest がどんな原理で動いているかの説明は省略します。使い方を理解して、Random Forest がどんな「クセ」を持っているのかイメージをつかんでください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SVvkIQ-lTcH"
      },
      "outputs": [],
      "source": [
        "# 機械学習モデルを作成する\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pMrKSgvlemJ"
      },
      "outputs": [],
      "source": [
        "# 学習する\n",
        "model.fit(x_train.reshape(-1, 1), t_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDaSqQLulirj"
      },
      "outputs": [],
      "source": [
        "# 訓練データを予測\n",
        "y_train = model.predict(x_train.reshape(-1, 1))\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pk0laMdrlnUt"
      },
      "outputs": [],
      "source": [
        "# 検証データを予測\n",
        "y_valid = model.predict(x_valid.reshape(-1, 1))\n",
        "y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yp5jHP6mlrtx"
      },
      "outputs": [],
      "source": [
        "# テストデータを予測\n",
        "y_test = model.predict(x_test.reshape(-1, 1))\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhWJIyIhl8ch"
      },
      "outputs": [],
      "source": [
        "# 訓練データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KuJUnKqmEKh"
      },
      "outputs": [],
      "source": [
        "# 検証データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfmzOIIQmFzo"
      },
      "outputs": [],
      "source": [
        "# テストデータの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqgpws1nBKBd"
      },
      "source": [
        "処理の流れは先程の SVM のときとほぼ一緒だということがお分かりいただけたでしょうか。違うことは、ハイパーパラメーターとして、SVMのときは（わざと）無茶苦茶なパラメータを設定した一方で、今回の Random Forest ではデフォルトの値（何も指定しなかったときに自動的に指定される値）を用いたことくらいです。\n",
        "\n",
        "今回もまた、訓練データの指標、検証データの指標、テストデータの指標を比べてみましょう。前回と違って、ほぼ変わらない値になったのではないでしょうか。\n",
        "\n",
        "どのような予測結果になったか図示してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eibcX2aLmJhn"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_train, t_train, marker='o', label=\"train\")\n",
        "plt.scatter(x_valid, t_valid, marker='x', label=\"valid\")\n",
        "plt.plot(x_test, t_test, label=\"test (true)\")\n",
        "plt.plot(x_test, y_test, label=\"test (predicted)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTIzm1d4B8oZ"
      },
      "source": [
        "さて、この結果は良い結果と言えるでしょうか？ overfitting は回避できているかもしれませんが、予測性能が高いかと言うと、そんなことはなさそうですね。\n",
        "\n",
        "そして、カクカクした不連続な曲線で間を取ろうとするのが Random Forest の「クセ」です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO4-lEDeCnfc"
      },
      "source": [
        "# K Neighbors\n",
        "\n",
        "同様にして、K Neighbors も試してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp15ZVqImVnp"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "model = KNeighborsRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XznM_AzImoy8"
      },
      "outputs": [],
      "source": [
        "# 学習する\n",
        "model.fit(x_train.reshape(-1, 1), t_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlA8jrrRmswm"
      },
      "outputs": [],
      "source": [
        "# 訓練データを予測\n",
        "y_train = model.predict(x_train.reshape(-1, 1))\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBSTBoThmxRR"
      },
      "outputs": [],
      "source": [
        "# 検証データを予測\n",
        "y_valid = model.predict(x_valid.reshape(-1, 1))\n",
        "y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5VecLijm14R"
      },
      "outputs": [],
      "source": [
        "# テストデータを予測\n",
        "y_test = model.predict(x_test.reshape(-1, 1))\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhyawz2im6AY"
      },
      "outputs": [],
      "source": [
        "# 訓練データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fC0MFKCkm9OE"
      },
      "outputs": [],
      "source": [
        "# 検証データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TofkqBl9nAzH"
      },
      "outputs": [],
      "source": [
        "# テストデータの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0hIB9bhnDmG"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_train, t_train, marker='o', label=\"train\")\n",
        "plt.scatter(x_valid, t_valid, marker='x', label=\"valid\")\n",
        "plt.plot(x_test, t_test, label=\"test (true)\")\n",
        "plt.plot(x_test, y_test, label=\"test (predicted)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loXBUn6PDO58"
      },
      "source": [
        "K Neighbors は、近くの K 個の点の値の間を取ろうとするので、こんな予測曲線になります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0rP4fSeDcOq"
      },
      "source": [
        "# Gradient Boosting\n",
        "\n",
        "非深層系の機械学習で最強クラスと噂される Gradient Boosting です（厳密にはその亜種である Light GBM が最強と噂されています）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8K4AHZKInzxq"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "model = GradientBoostingRegressor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czHTJOWnn9Ic"
      },
      "outputs": [],
      "source": [
        "# 学習する\n",
        "model.fit(x_train.reshape(-1, 1), t_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16ns9EQaoCOv"
      },
      "outputs": [],
      "source": [
        "# 訓練データを予測\n",
        "y_train = model.predict(x_train.reshape(-1, 1))\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGWJyjtEoHvV"
      },
      "outputs": [],
      "source": [
        "# 検証データを予測\n",
        "y_valid = model.predict(x_valid.reshape(-1, 1))\n",
        "y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dajINXgoLEK"
      },
      "outputs": [],
      "source": [
        "# テストデータを予測\n",
        "y_test = model.predict(x_test.reshape(-1, 1))\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2Y8_KrUoOJg"
      },
      "outputs": [],
      "source": [
        "# 訓練データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc75AnTboS5c"
      },
      "outputs": [],
      "source": [
        "# 検証データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCPGIig8oV2H"
      },
      "outputs": [],
      "source": [
        "# テストデータの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_elHMsxoZdn"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_train, t_train, marker='o', label=\"train\")\n",
        "plt.scatter(x_valid, t_valid, marker='x', label=\"valid\")\n",
        "plt.plot(x_test, t_test, label=\"test (true)\")\n",
        "plt.plot(x_test, y_test, label=\"test (predicted)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWqSQ7TEEVYJ"
      },
      "source": [
        "Gradient Boosting の「クセ」はお分かりでしょうか。最強クラスかもしれませんが、ハイパーパラメーターを適切にチューニングしないと、こんな感じに overfitting します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCn2I83zEuRj"
      },
      "source": [
        "# MLP\n",
        "\n",
        "深層学習の中で最も単純なのが MLP です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYb0lZBwom2_"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "params = {\"hidden_layer_sizes\":[100]*10, \"max_iter\":530000}\n",
        "model = MLPRegressor(**params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvyU1PWyoxXu"
      },
      "outputs": [],
      "source": [
        "# 学習する\n",
        "model.fit(x_train.reshape(-1, 1), t_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiHjOSsgo1xr"
      },
      "outputs": [],
      "source": [
        "# 訓練データを予測\n",
        "y_train = model.predict(x_train.reshape(-1, 1))\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3NIM0qoo72B"
      },
      "outputs": [],
      "source": [
        "# 検証データを予測\n",
        "y_valid = model.predict(x_valid.reshape(-1, 1))\n",
        "y_valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF2d9BJyo_KR"
      },
      "outputs": [],
      "source": [
        "# テストデータを予測\n",
        "y_test = model.predict(x_test.reshape(-1, 1))\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk9vrnsbpDg6"
      },
      "outputs": [],
      "source": [
        "# 訓練データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXg-zMBnpHa2"
      },
      "outputs": [],
      "source": [
        "# 検証データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_valid, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdD0uY71pKKG"
      },
      "outputs": [],
      "source": [
        "# テストデータの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDXpAfDLpQjl"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_train, t_train, marker='o', label=\"train\")\n",
        "plt.scatter(x_valid, t_valid, marker='x', label=\"valid\")\n",
        "plt.plot(x_test, t_test, label=\"test (true)\")\n",
        "plt.plot(x_test, y_test, label=\"test (predicted)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un4Acz1VHR9r"
      },
      "source": [
        "さて、色んな機械学習モデルを試すのは、以上です。\n",
        "\n",
        "ここまでで、「検証データって、必要なの？テストデータだけ使えば十分じゃないの？」と疑問を持たれた方がいらっしゃるかもしれません。それは、次の「グリッドサーチ」以降で分かると思います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0tvRYrZcc00"
      },
      "source": [
        "# グリッドサーチ\n",
        "\n",
        "訓練データには適合していても、検証データやテストデータには適合していない学習例が数多く算出されました。これが「過剰適合」(overfitting) の例です。\n",
        "\n",
        "上記の例では、機械学習時に用いるハイパーパラメーターをわざと変な値にしたり、デフォルト値のまま使ったりしています。\n",
        "\n",
        "実際には、ハイパーパラメーターを良い感じにチューニングして使います。その方法の一つである「グリッドサーチ」を使って、SVMのハイパーパラメーターをチューニングする例を以下に実演します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeKRtqIXoQX6"
      },
      "outputs": [],
      "source": [
        "# SVMのハイパーパラメータの一つ gamma を７個用意します。\n",
        "gammas = [10**n for n in range(-3, 4)]\n",
        "gammas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6LPwzbroEmD"
      },
      "outputs": [],
      "source": [
        "# SVMのハイパーパラメータの一つ C を７個用意します。\n",
        "Cs = [10**n for n in range(-3, 4)]\n",
        "Cs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3arEsCSLKpcw"
      },
      "source": [
        "用意した７個のgammaと、７個のCの全組み合わせについてSVMモデルを作成し、最も性能の良いモデルを選び出します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INtgXp91mkXy"
      },
      "outputs": [],
      "source": [
        "best_valid_score = None # 最も良いスコアを記録するための変数\n",
        "best_model = None # 最も良いモデルを保存するための変数\n",
        "score_record = {} # グリッドサーチの全結果を保存するための変数\n",
        "\n",
        "for gamma in gammas: # 全ての gamma に対して\n",
        "    k1 = \"g={}\".format(gamma)\n",
        "    score_record[k1] = {}\n",
        "\n",
        "    for C in Cs: # 全ての C に対して\n",
        "        k2 = \"C={}\".format(C)\n",
        "\n",
        "        # 訓練データを用いて学習\n",
        "        model = SVR(kernel=\"rbf\", C=C, gamma=gamma)\n",
        "        model.fit(x_train.reshape(-1, 1), t_train)\n",
        "\n",
        "        # 検証データを予測\n",
        "        y_valid = model.predict(x_valid.reshape(-1, 1))\n",
        "        mae_valid = mean_absolute_error(y_valid, t_valid)\n",
        "        score_record[k1][k2] = mae_valid\n",
        "\n",
        "        # 検証データの予測性能が最も高いモデルを保存\n",
        "        if best_valid_score is None or best_valid_score > mae_valid:\n",
        "            best_valid_score = mae_valid\n",
        "            best_model = model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFihT6GhLuHe"
      },
      "source": [
        "７個のgammaと７個のCに対して作成した全モデルの性能は次のようになります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SW7zDPG6IQR-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(score_record).style.background_gradient(axis=None, cmap=\"jet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFt5pSvtL4qy"
      },
      "source": [
        "ベストモデル賞の栄誉に輝いたのはこのモデルです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYAqyqihmEHw"
      },
      "outputs": [],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxOcFCJXqfzP"
      },
      "outputs": [],
      "source": [
        "# 訓練データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_train, best_model.predict(x_train.reshape(-1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2MqLSkDqp29"
      },
      "outputs": [],
      "source": [
        "# 検証データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_valid, best_model.predict(x_valid.reshape(-1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUF5R9twquqY"
      },
      "outputs": [],
      "source": [
        "# テストデータの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_test, best_model.predict(x_test.reshape(-1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOPX7vHbqcv-"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_train, t_train, marker='o', label=\"train\")\n",
        "plt.scatter(x_valid, t_valid, marker='x', label=\"valid\")\n",
        "plt.plot(x_test, f(x_test), label=\"test (true)\")\n",
        "plt.plot(x_test, best_model.predict(x_test.reshape(-1, 1)), label=\"test (SVM)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIT0BzGJdI08"
      },
      "source": [
        "ここでは、「**訓練データを使って学習**」して、「**検証データの予測性能が高いモデルを選んでいる**」ことに注意してください。一方、テストデータは学習に使っていません。\n",
        "\n",
        "# Optuna を用いたハイパーパラメーターチューニング\n",
        "\n",
        "グリッドサーチでは、（普通は複数種類ある）ハイパーパラメーター毎に、いくつかの候補の「値」を事前に決めておいて、その候補のハイパーパラメーターの全組み合わせに対して学習を行ない、最も性能の良い組み合わせを選びます。\n",
        "\n",
        "これに対して、Optuna というツールを使えば、ハイパーパラメーターの「値の範囲」を事前に決めておけばハイパーパラメーターチューニングができるようになります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe9gsMXeISWs"
      },
      "outputs": [],
      "source": [
        "# Optuna のインストール\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tGRdEmqfQ_d"
      },
      "source": [
        "次のコードで、SVM を Optuna でハイパーパラメーターチューニングするためのクラスを定義します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLymUotjIckK"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "class best_SVR:\n",
        "    def __init__(self, x_train, x_valid, t_train, t_valid):\n",
        "        # 訓練データを格納\n",
        "        self.x_train = x_train\n",
        "        self.t_train = t_train\n",
        "\n",
        "        # 検証データを格納\n",
        "        self.x_valid = x_valid\n",
        "        self.t_valid = t_valid\n",
        "\n",
        "        # ベストモデルとスコアを格納\n",
        "        self.best_score = None\n",
        "        self.best_model = None\n",
        "\n",
        "    def __call__(self, trial):\n",
        "        # チューニングしたいパラメータの範囲を設定\n",
        "        model_params = {}\n",
        "        model_params[\"C\"] = trial.suggest_float(\"C\", 1e-10, 1e10, log=True)\n",
        "        model_params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-10, 1e10, log=True)\n",
        "\n",
        "        # SVMモデルを作成し訓練データを学習\n",
        "        model = SVR(**model_params)\n",
        "        model.fit(self.x_train.reshape(-1, 1), self.t_train)\n",
        "\n",
        "        # 検証データの予測性能を評価\n",
        "        score = mean_absolute_error(model.predict(x_valid.reshape(-1, 1)), self.t_valid)\n",
        "\n",
        "        # ベストスコアが出れば、そのベストモデルを記録\n",
        "        if self.best_model is None or self.best_score > score:\n",
        "            self.best_score = score\n",
        "            self.best_model = copy.deepcopy(model)\n",
        "\n",
        "        # スコアを返す\n",
        "        return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6mkY9xYfgsS"
      },
      "source": [
        "次のコードで、学習を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eO3tFpOOIh5H"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "# 各種設定\n",
        "optuna.logging.set_verbosity(optuna.logging.WARN)\n",
        "timeout = 50\n",
        "n_trials = 100\n",
        "show_progress_bar = True\n",
        "\n",
        "# 目的変数（最小化または最大化したい値）の設定\n",
        "objective = best_SVR(x_train, x_valid, t_train, t_valid)\n",
        "\n",
        "# 学習環境を立ち上げる\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "\n",
        "# 学習する\n",
        "study.optimize(\n",
        "        objective,\n",
        "        timeout=timeout,\n",
        "        n_trials=n_trials,\n",
        "        show_progress_bar=show_progress_bar,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Big9B7ggfnui"
      },
      "source": [
        "グリッドサーチは指定した全組み合わせを満遍なく計画通りに探索するのに対して、Optunaでは、有望そうであると思われた範囲を重点的に探索し、グリッドサーチでは到達するのが難しい値に到達することができます。図示しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fLMfrIMy6jg"
      },
      "outputs": [],
      "source": [
        "# 性能評価指標の推移\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([trial.value for trial in study.trials], label='value')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g63Pqp2jzJlB"
      },
      "outputs": [],
      "source": [
        "# C の推移\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([trial.params['C'] for trial in study.trials], label='C')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RNW8Lhlzp4T"
      },
      "outputs": [],
      "source": [
        "# gamma の推移\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot([trial.params['gamma'] for trial in study.trials], label='gamma')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd6cHqfjz17O"
      },
      "outputs": [],
      "source": [
        "# C と gamma の推移\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(\n",
        "    [trial.params['gamma'] for trial in study.trials], \n",
        "    [trial.params['C'] for trial in study.trials], \n",
        "    marker='o',\n",
        "    alpha=0.8)\n",
        "plt.grid()\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"Gamma\")\n",
        "plt.ylabel(\"C\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr_RhLHEQLlv"
      },
      "source": [
        "グリッドサーチでは到達が難しそうな場所を探索できていることがお分かりでしょうか。\n",
        "\n",
        "ベストモデル賞の栄誉に輝いたのはこのモデルです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf1gT5U2s176"
      },
      "outputs": [],
      "source": [
        "best_model = objective.best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJPEtJe-tBSI"
      },
      "outputs": [],
      "source": [
        "# 訓練データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_train, best_model.predict(x_train.reshape(-1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88YFQ-tPtGGz"
      },
      "outputs": [],
      "source": [
        "# 検証データの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_valid, best_model.predict(x_valid.reshape(-1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho4f7zmRtKH3"
      },
      "outputs": [],
      "source": [
        "# テストデータの予測性能の評価（平均絶対誤差）\n",
        "mean_absolute_error(t_test, best_model.predict(x_test.reshape(-1, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aP44m_5tODt"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_train, t_train, marker='o', label=\"train\")\n",
        "plt.scatter(x_valid, t_valid, marker='x', label=\"valid\")\n",
        "plt.plot(x_test, f(x_test), label=\"test (true)\")\n",
        "plt.plot(x_test, best_model.predict(x_test.reshape(-1, 1)), label=\"test (SVM)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdmJTLU-QcVN"
      },
      "source": [
        "# 課題\n",
        "\n",
        "下記の関数に対して、上記のコードを全て動かしてください。その結果について説明してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4SftixbQixd"
      },
      "outputs": [],
      "source": [
        "f = lambda x: 0.2*np.sin(x) + 0.3*np.cos(2*x) + 0.5*np.sin(2/3*x) + 0.2*np.sin(x/3) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHgilYqfS_jq"
      },
      "source": [
        "<b>提出方法：</b>\n",
        "\n",
        "下記のいずれかの方法で提出してください。\n",
        "\n",
        "- Google Colaboratory 上で動作させたコードを ikemenmaskot@gmail.com に「共有」\n",
        "\n",
        "- Jupyter Notebook 上で動作させたコードを ipynb 形式または html 形式にして ikemenmaskot@gmail.com に「メール送信」"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIUNTfqhQ1FZ"
      },
      "source": [
        "# 次回\n",
        "\n",
        "第２回は「適用範囲」というテーマでお話ししたいと思います。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}