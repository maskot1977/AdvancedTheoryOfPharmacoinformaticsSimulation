{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maskot1977/AdvancedTheoryOfPharmacoinformaticsSimulation/blob/MsukGWXrhsrZMkF6/%E3%83%95%E3%82%A1%E3%83%BC%E3%83%9E%E3%82%B3%E3%82%A4%E3%83%B3%E3%83%95%E3%82%A9%E3%83%9E%E3%83%86%E3%82%A3%E3%82%AF%E3%82%B7%E3%82%B7%E3%83%9F%E3%83%A5%E3%83%AC%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E7%89%B9%E8%AB%962.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWOKkTfjJnxI"
      },
      "source": [
        "# ファーマコインフォマティクスシミュレーション特論\n",
        "\n",
        "小寺正明\n",
        "\n",
        "# 第2回　適用範囲\n",
        "\n",
        "機械学習モデルの性能を考えるにあたって「過剰適合」を取り扱いましたが、「適用範囲」（Applicability Domain, AD）も重要な視点です。\n",
        "\n",
        "# １次元データ\n",
        "\n",
        "適用範囲とは何か、まずは１次元で考えてみましょう。乱数を用いて、次のようなデータを用意します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHyGZzARi5v9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.concatenate([np.random.normal(20, 10, (10, 1)), np.random.normal(80, 10, (10, 1))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmkRwWf7H5oH"
      },
      "source": [
        "具体的には、次のような数字の集合です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTK3P6SVjD26"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orKMcGpyIE9I"
      },
      "source": [
        "データの分布をヒストグラムとして表すと、次のようになります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhDWeAsUjTpI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(X)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ivMtHT8IaWK"
      },
      "source": [
        "ヒストグラムの下に、一次元散布図としてデータをプロットしてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91ebah0ljcBw"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X, [-0.5 for x in X], alpha=0.5)\n",
        "plt.hist(X)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Y1xHCdIvYq"
      },
      "source": [
        "以上のデータを用いて、適用範囲について考えてみたいと思います。\n",
        "\n",
        "# K近傍法（k-NearestNeighbors, k-NN）\n",
        "\n",
        "おそらく最もわかりやすい K近傍法 を使ってみます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MH5eMtZqjgUj"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "n_neighbors = 3 # 自分自身を含めて k 番目に近い点までを「近傍」とみなす\n",
        "model = NearestNeighbors(n_neighbors=n_neighbors) # モデルの立ち上げ\n",
        "model.fit(X) # X のデータ構造を学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6A11ysJWgkG"
      },
      "source": [
        "学習の結果をもとに、X のデータを距離データとインデックスデータに変換します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsYH__xPjmDQ"
      },
      "outputs": [],
      "source": [
        "distances, indices = model.kneighbors(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEMZLunWfUgT"
      },
      "source": [
        "インデックスデータには、自分自身を含めて k 番目に近い点までのインデックスが蓄えられます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGdGMtlWjuWF"
      },
      "outputs": [],
      "source": [
        "indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv8GX0huez2v"
      },
      "source": [
        "距離データには、（インデックスデータに対応する）自分を含めて k 番目に近い点までの距離の情報が蓄えられます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp5281xMjoPP"
      },
      "outputs": [],
      "source": [
        "distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9zpXZmUPDvA"
      },
      "source": [
        "上の計算結果から、n_neighbors 番目に近い点までの距離をリストにしてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZrvLfvOjyC4"
      },
      "outputs": [],
      "source": [
        "distances[:, n_neighbors - 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMW-Xk4zPWp3"
      },
      "source": [
        "それを小さい順にソートします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "METO1u43j3De"
      },
      "outputs": [],
      "source": [
        "sorted(distances[:, n_neighbors - 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7p8VBC_PbTC"
      },
      "source": [
        "ここから、たとえば out = 0.2 として、全データのうち 20% を「外れ値」とみなしたときに、どこを閾値とすれば良いかを考えます。実際にはこの out = 0.2 という値は、0.05 など、もっと小さい値を設定するのが普通なのですが、今回は説明のためにわざと大きい値を設定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKqSQtVDj49B"
      },
      "outputs": [],
      "source": [
        "out = 0.2\n",
        "int((len(X) - 1) * (1 - out))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcIcc8PfP9tS"
      },
      "source": [
        "この順位のdistanceを次のように取得して、閾値とします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-uDTijvj8Sj"
      },
      "outputs": [],
      "source": [
        "out = 0.2\n",
        "threshold = sorted(distances[:, n_neighbors - 1])[int((len(X) - 1) * (1 - out))]\n",
        "threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpiqnFKfQznz"
      },
      "source": [
        "上記の値を閾値として、それよりも大きいdistanceならば外れ値、すなわち「適用範囲外」とみなすわけです。\n",
        "\n",
        "以上の計算をもとに、適用範囲を可視化しましょう。まず、Xを k neighbor distanceに変換する関数を次のように定義します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuqT4aXxkRmX"
      },
      "outputs": [],
      "source": [
        "def transform(x):\n",
        "    distances, indices = model.kneighbors(x)\n",
        "    return distances[:, n_neighbors - 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ3UkjOtRsdu"
      },
      "source": [
        "Xの定義域を 0 から 100 までとします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDkcD85xkUD5"
      },
      "outputs": [],
      "source": [
        "x_latent = np.linspace(0, 100, 101).reshape(101, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNOMPNOkSc_1"
      },
      "source": [
        "データXと、閾値と、k neighbor distanceとの関係を図示すると次のようになります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54LOb6pRkW1X"
      },
      "outputs": [],
      "source": [
        "plt.plot(x_latent, transform(x_latent), label=\"k neighbor distance\")\n",
        "plt.plot([0, 100], [threshold, threshold], label=\"threshold\")\n",
        "plt.scatter(X, [-0.5 for x in X], alpha=0.5, label=\"data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbdJjYL5SwEh"
      },
      "source": [
        "k neighbor distance の値が小さい領域が、データ密度の高い領域になります。そして、その値が閾値以下の部分は、十分にデータ密度が高く、何か予測を行った場合に、その予測が信頼できるであろう領域、つまり「適用範囲」であるとみなすわけです。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeiBaTtYTST6"
      },
      "source": [
        "# One Class SVM (OCSVM)\n",
        "\n",
        "適用範囲の定義の仕方は他にもたくさんあります。今回はもうひとつだけ、One Class SVM という方法について簡単にお示ししましょう。One Class SVM は名前の通り SVM を応用したもので、外れ値なのかそうじゃないのかをSVMで分類するモデルです。学習は次のように行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucl3jmxhkeHI"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import OneClassSVM\n",
        "\n",
        "model = OneClassSVM() # モデルの立ち上げ\n",
        "model.fit(X) # X のデータ構造を学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfyvT8vFT_ky"
      },
      "source": [
        "SVMでは、分類予測結果を判断するためのスコアを次のように算出します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwlZCb15khyJ"
      },
      "outputs": [],
      "source": [
        "score = model.decision_function(X)\n",
        "score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plR6Y61FUgib"
      },
      "source": [
        "そーっとソートしてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiDV6DpokmAE"
      },
      "outputs": [],
      "source": [
        "sorted(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxFI333FU7hS"
      },
      "source": [
        "k近傍法では distance が小さいほど「近傍」である、つまりデータ密度が高いということでしたが、OCSVM（および他のほぼ全ての方法）では、スコアが大きいほどデータ密度が高いという尺度になります。ですので、 out = 0.2 つまりデータの 20% を「外れ値」とみなしたい場合の閾値は次のようにして決定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXdrDmaZk3VM"
      },
      "outputs": [],
      "source": [
        "out = 0.2\n",
        "int((len(X) - 1) * out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8auoy6xk6_H"
      },
      "outputs": [],
      "source": [
        "out = 0.2\n",
        "threshold = sorted(score)[int((len(X) - 1) * out)]\n",
        "threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6PeUZpPVI1I"
      },
      "source": [
        "上記の閾値をよりも低いスコアのものを「外れ値」つまり「適用範囲外」とみなすわけです。寿司しましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nH9TL9dWk_jS"
      },
      "outputs": [],
      "source": [
        "plt.plot(x_latent, model.decision_function(x_latent))\n",
        "plt.plot([0, 100], [threshold, threshold])\n",
        "plt.scatter(X, [1 for x in X], alpha=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LheZtaJ9V-bW"
      },
      "source": [
        "同じデータでも、k近傍法とOCSVMで適用範囲の領域が若干異なることが分かります。どっちが良いかや、何％を外れ値とみなせば良いかなどは、ケースバイケースで検討してみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgm_Xz_djbhP"
      },
      "source": [
        "# ２次元データ\n",
        "\n",
        "それでは、今度は２次元データを描画しながら<s>遊んで</s>学んでみましょう。まずは、２次元データを可視化するための関数を用意しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmo428G8Ik_I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def heatmap(f, x_min=-12, x_max=12, y_min=-12, y_max=12, h=0.1, \n",
        "             axes=[0, 1, 1, 1], epsilon=None,\n",
        "             drawline=False, cmap=plt.cm.jet):\n",
        "\n",
        "    def get_Z(f, axis):\n",
        "        if axis == 1:\n",
        "            X = []\n",
        "            for y in np.arange(y_min, y_max, h):\n",
        "                for x in np.arange(x_min, x_max, h):\n",
        "                    X.append([x, y])\n",
        "            X = np.array(X)\n",
        "            Z = f(X).reshape(\n",
        "                len(np.arange(x_min, x_max, h)), \n",
        "                len(np.arange(y_min, y_max, h))\n",
        "                )\n",
        "        else:\n",
        "            Z = [[f([x, y]) for x, y in zip(xx, yy)] for xx, yy in zip(x_mg,y_mg)]\n",
        "        return Z\n",
        "\n",
        "    x_mg, y_mg = np.meshgrid(\n",
        "        np.arange(x_min, x_max, h), \n",
        "        np.arange(y_min, y_max, h)\n",
        "        )\n",
        "    if type(f) == list:\n",
        "        for i, ff in enumerate(f):\n",
        "            if axes[i] == -1:\n",
        "                plt.contour(x_mg, y_mg, get_Z(ff, 1), colors='black')\n",
        "            elif i == 0:\n",
        "                Z = np.array(get_Z(ff, axes[i]))\n",
        "            else:\n",
        "                Z -= np.array(get_Z(ff, axes[i]))\n",
        "        Z = Z.tolist()\n",
        "            \n",
        "    else:\n",
        "            Z = get_Z(f, axes[0])\n",
        "\n",
        "    if epsilon:\n",
        "        Z = np.array(Z)\n",
        "        Z = np.ma.array(Z, mask=np.abs(Z) <= epsilon)\n",
        "        cmap.set_bad((1, 1, 1, 1))  # 無効な値に対応する色\n",
        "        #cmap.set_bad((0, 0, 0, 1))  # 無効な値に対応する色\n",
        "\n",
        "    plt.axes().set_aspect('equal')\n",
        "    if drawline:\n",
        "        plt.contour(x_mg, y_mg, Z, colors='black')\n",
        "    plt.imshow(Z, origin='lower', extent=[x_min, x_max, y_min, y_max], cmap=cmap)\n",
        "    plt.colorbar()\n",
        "    #plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDee0ppqPE2r"
      },
      "source": [
        "そうすると、たとえば次のような２変数関数を図示できます。これらの２変数関数が、予測すべき「真の現象」であるものとします。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGcCMkn5J5gM"
      },
      "outputs": [],
      "source": [
        "f1 = lambda x: np.sqrt(np.abs(np.sqrt(np.abs(np.minimum((x[0]/3)**2 + (x[1]/3)**2 - 1, (np.abs(x[0]/3) - 0.95)**2 + (x[1]/3 - 0.95)**2 - 0.55**2)))))\n",
        "f2 = lambda x: np.sqrt(x[0]**2 + (x[1] - np.sqrt(np.abs(x[0])))**2)\n",
        "f3 = lambda x: np.linalg.norm([x[0], x[1]]) - np.cos(6 * np.arctan2(x[0],  x[1]))\n",
        "f4 = lambda x: np.linalg.norm([x[0], x[1]]) - 2* np.arctan2(x[0],  x[1]) \n",
        "\n",
        "func = [f1, f2, f3, f4]\n",
        "for f in func:\n",
        "    heatmap(f, drawline=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXJ4XL3FY1Q7"
      },
      "source": [
        "# training data, validation data, test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwRcBN_e-RyS"
      },
      "source": [
        "ところが、現実に測定可能なのは「真の現象」の中のほんのいくつかの点でしかありません。現実に測定した点が次のような分布を持っていたとしましょう。これを training data とします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BU4gouF9Liby"
      },
      "outputs": [],
      "source": [
        "X_train = np.random.rand(2, 20) * 10\n",
        "\n",
        "plt.scatter(X_train.T[:, 0], X_train.T[:, 1], label=\"train\")\n",
        "plt.axes().set_aspect('equal')\n",
        "plt.xlim([-12, 12])\n",
        "plt.ylim([-12, 12])\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS6CovETilMY"
      },
      "source": [
        "これに対して、実際に予測したいデータは、学習用データとは異なる分布を持つ場合があります。このような場合に、適用範囲外の予測結果はどのようになるか見てみましょう。\n",
        "\n",
        "ちなみに、適用範囲内の予測を「内挿」、適用範囲外の予測を「外挿」と呼ぶことがあります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWRDon46MOXP"
      },
      "outputs": [],
      "source": [
        "X_valid = np.random.rand(2, 20) * 15 - 5\n",
        "X_test = np.random.rand(2, 20) * 15 - 10\n",
        "\n",
        "plt.scatter(X_train.T[:, 0], X_train.T[:, 1], marker='o', label=\"train\")\n",
        "plt.scatter(X_valid.T[:, 0], X_valid.T[:, 1], marker='x', label=\"valid\")\n",
        "plt.scatter(X_test.T[:, 0], X_test.T[:, 1], marker='s', label=\"test\")\n",
        "plt.axes().set_aspect('equal')\n",
        "plt.xlim([-12, 12])\n",
        "plt.ylim([-12, 12])\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6o4xeTBZY9i"
      },
      "source": [
        "# データ密度を定義するさまざまな手法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo0j1Y_WOA82"
      },
      "source": [
        "このようなとき、学習に用いたデータの密度の濃い部分だけを信用するということをよく行います。その「学習データの密度」を計算する手法として、\n",
        "\n",
        "- K-Nearest Neighbors (KNN)\n",
        "- One-Class SVM (OCSVM)\n",
        "- Isolation Forest (IF)\n",
        "- Local Outlier Factor (LOF)\n",
        "- Elliptic Envelope (EE)\n",
        "\n",
        "などの手法があります。試しに使ってみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0Sq480JKBzr"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.covariance import EllipticEnvelope\n",
        "\n",
        "class KNN:\n",
        "    def __init__(self, n_neighbors=5, outlier_fraction=0.1, algorithm='ball_tree'):\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.outlier_fraction = outlier_fraction\n",
        "        self.model = False\n",
        "        self.algorithm = algorithm\n",
        "        self.distances = False\n",
        "        self.indices = False\n",
        "        self.threshold = False\n",
        "        self.len_data = False\n",
        "        \n",
        "    def fit(self, X):\n",
        "        self.len_data = len(X)\n",
        "        self.model = NearestNeighbors(\n",
        "            n_neighbors=self.n_neighbors, \n",
        "            algorithm=self.algorithm \n",
        "            ).fit(X)\n",
        "        self.distances, self.indices = self.model.kneighbors(X)\n",
        "        self.threshold = sorted(\n",
        "            self.distances[:, self.n_neighbors - 1]\n",
        "            )[int((self.len_data - 1) * (1 - self.outlier_fraction))]\n",
        "\n",
        "    def transform(self, x):\n",
        "        self.distances, self.indices = self.model.kneighbors(x)\n",
        "        return self.distances[:, self.n_neighbors - 1]\n",
        "\n",
        "    def transform_bin(self, x):\n",
        "        self.transform(x)\n",
        "        self.Z = self.distances[:, self.n_neighbors - 1]\n",
        "        return np.where(self.Z >= self.threshold, 0, 1)\n",
        "\n",
        "class AVDetector:\n",
        "    def __init__(self, model=OneClassSVM(), outlier_fraction=0.1, ):\n",
        "        self.model = model\n",
        "        self.outlier_fraction = outlier_fraction\n",
        "        self.threshold = False\n",
        "        self.len_data = False\n",
        "    \n",
        "    def fit(self, X):\n",
        "        self.len_data = len(X)\n",
        "        self.model.fit(X)\n",
        "        self.threshold = sorted(\n",
        "            self.model.decision_function(X)\n",
        "            )[int((self.len_data - 1) * self.outlier_fraction)]\n",
        "\n",
        "    def transform(self, x):\n",
        "        return self.model.decision_function(x)\n",
        "\n",
        "    def transform_bin(self, x):\n",
        "        self.Z = self.model.decision_function(x)\n",
        "        return np.where(self.Z >= self.threshold, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70nrxkFqBd_i"
      },
      "source": [
        "先ほどのデータ分布に対して、各手法がどのような適用範囲を定義するか見てみましょう。太線の内側が「適用範囲」とみなされることになります。どの手法が最も良いかと言われても、ケースバイケースとしか言いようがないかも知れません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBaRoaMNLnSQ"
      },
      "outputs": [],
      "source": [
        "avd_dict = {}\n",
        "for avd_name, avd in [\n",
        "            [\"KNN\", KNN()], \n",
        "            [\"OneClassSVM\", AVDetector(model=OneClassSVM())], \n",
        "            [\"IsolationForest\", AVDetector(model=IsolationForest())],\n",
        "            [\"LocalOutlierFactor\", AVDetector(model=LocalOutlierFactor(novelty=True))],\n",
        "            [\"EllipticEnvelope\", AVDetector(model=EllipticEnvelope())]\n",
        "]:\n",
        "    avd.fit(X_train.T)\n",
        "    avd_dict[avd_name] = avd\n",
        "    plt.title(avd_name)\n",
        "    plt.scatter(X_train.T[:, 0], X_train.T[:, 1])\n",
        "    heatmap([avd.transform, avd.transform_bin], axes=[1, -1], drawline=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoilTkIaZ4iU"
      },
      "source": [
        "機械学習を用いた予測手法にもさまざまな「クセ」があるように、適用範囲を極める手法にもさまざまな「クセ」があることがお分かりいただけるのではないかと思います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fANLAbGjCumC"
      },
      "source": [
        "# 機械学習による予測と、適用範囲との関係\n",
        "\n",
        "それでは、さまざまな機械学習手法に対して、典型的な予測結果の傾向と、適用範囲との関係を見ていきましょう。その前に、結果表示用の関数を定義します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khJ8vVggMbNG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, balanced_accuracy_score\n",
        "\n",
        "def compare_model(func, predict, cmap=plt.cm.jet, epsilon=0.1, metrics=mean_squared_error, alpha=1.0):\n",
        "    metrics_train = metrics(Y_train, predict(X_train.T))\n",
        "    metrics_valid = metrics(Y_valid, predict(X_valid.T))\n",
        "    metrics_test = metrics(Y_test, predict(X_test.T))\n",
        "\n",
        "    plt.title(\"True function\")\n",
        "    plt.scatter(X_train.T[:, 0], X_train.T[:, 1], marker='o', alpha=alpha)\n",
        "    plt.scatter(X_valid.T[:, 0], X_valid.T[:, 1], marker='^', alpha=alpha)\n",
        "    plt.scatter(X_test.T[:, 0], X_test.T[:, 1], marker='s', alpha=alpha)\n",
        "    heatmap([func, avd.transform_bin], axes=[0, -1], drawline=False, cmap=cmap)\n",
        "\n",
        "    plt.title(\"Predicted function\")\n",
        "    plt.scatter(X_train.T[:, 0], X_train.T[:, 1], marker='o', alpha=alpha)\n",
        "    plt.scatter(X_valid.T[:, 0], X_valid.T[:, 1], marker='^', alpha=alpha)\n",
        "    plt.scatter(X_test.T[:, 0], X_test.T[:, 1], marker='s', alpha=alpha)\n",
        "    heatmap([predict, avd.transform_bin], axes=[1, -1], drawline=False, cmap=cmap)\n",
        "\n",
        "    plt.title(\"train={0:.2f}, test={1:.2f}, valid={2:.2f}\".format(metrics_train, metrics_test, metrics_valid))\n",
        "    plt.scatter(X_train.T[:, 0], X_train.T[:, 1], marker='o', alpha=alpha)\n",
        "    plt.scatter(X_valid.T[:, 0], X_valid.T[:, 1], marker='^', alpha=alpha)\n",
        "    plt.scatter(X_test.T[:, 0], X_test.T[:, 1], marker='s', alpha=alpha)\n",
        "    heatmap([predict, func, avd.transform_bin], axes=[1, 0, -1], drawline=False, cmap=cmap, epsilon=epsilon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHWc9OGxDJSV"
      },
      "source": [
        "適用範囲を定義する手法を選択します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q640iHIMeaX"
      },
      "outputs": [],
      "source": [
        "avd = avd_dict[\"OneClassSVM\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRZgwNMpDMw1"
      },
      "source": [
        "予測したい２変数関数を選択します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNaR-IdRMUlA"
      },
      "outputs": [],
      "source": [
        "f = f1\n",
        "Y_train = f(X_train)\n",
        "Y_valid = f(X_valid)\n",
        "Y_test = f(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sTrhM3tDjiy"
      },
      "source": [
        "それでは、順次、いろんな機械学習手法を使ってみましょう。なお、ここではハイパーパラメーターチューニングを省略します。\n",
        "\n",
        "３つの図が現れますが、上から順に、\n",
        "\n",
        "- 真の現象（２変数関数）\n",
        "- 予測値\n",
        "- 両者のズレ\n",
        "\n",
        "を表します。ズレの小さい部分は白色になります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlAXfahhV2Jd"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "model = SVR()\n",
        "model.fit(X_train.T, Y_train)\n",
        "compare_model(f, model.predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_K4NcCnMhBx"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X_train.T, Y_train)\n",
        "compare_model(f, model.predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_1JzqkVDM54"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "model = KNeighborsRegressor()\n",
        "model.fit(X_train.T, Y_train)\n",
        "compare_model(f, model.predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJKSnP3gFyHq"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "model = GradientBoostingRegressor()\n",
        "model.fit(X_train.T, Y_train)\n",
        "compare_model(f, model.predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o1aWRaKV8_v"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "model = MLPRegressor(hidden_layer_sizes=[100]*10)\n",
        "model.fit(X_train.T, Y_train)\n",
        "compare_model(f, model.predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVcVi-MhGBpA"
      },
      "source": [
        "各々の学習モデルの「くせ」、そしてそれと適用範囲との関係がなんとなく把握できたのではないでしょうか。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26tc_paGbFyK"
      },
      "source": [
        "# Optuna を用いたハイパーパラメーターチューニング\n",
        "\n",
        "最後に、Optuna を用いたハイパーパラメーターチューニングを行いながら、適用範囲との関係を見てみたいと思います。まずは Optuna のインストールから。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ab6ZZfLmzgfE"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi3yqucHiwAw"
      },
      "source": [
        "# データと適用範囲"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL-PoW_-g1WN"
      },
      "source": [
        "そして、データの数も適当に増やしてみましょう。train, validation, test で分布域が異なるようにわざとデータを作ったところがポイントです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-QXnIeBKtcB"
      },
      "outputs": [],
      "source": [
        "X_train = np.random.rand(2, 100) * 10\n",
        "X_valid = np.random.rand(2, 100) * 12 - 4\n",
        "X_test = np.random.rand(2, 100) * 15 - 10\n",
        "\n",
        "plt.scatter(X_train.T[:, 0], X_train.T[:, 1], marker='o', label=\"train\")\n",
        "plt.scatter(X_valid.T[:, 0], X_valid.T[:, 1], marker='x', label=\"valid\")\n",
        "plt.scatter(X_test.T[:, 0], X_test.T[:, 1], marker='s', label=\"test\")\n",
        "plt.axes().set_aspect('equal')\n",
        "plt.xlim([-12, 12])\n",
        "plt.ylim([-12, 12])\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opetvpoVi3lj"
      },
      "source": [
        "さまざまな手法で適用範囲を定義すると次のようになります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-FJ4Idih05l"
      },
      "outputs": [],
      "source": [
        "avd_dict = {}\n",
        "for avd_name, avd in [\n",
        "            [\"KNN\", KNN()], \n",
        "            [\"OneClassSVM\", AVDetector(model=OneClassSVM())], \n",
        "            [\"IsolationForest\", AVDetector(model=IsolationForest())],\n",
        "            [\"LocalOutlierFactor\", AVDetector(model=LocalOutlierFactor(novelty=True))],\n",
        "            [\"EllipticEnvelope\", AVDetector(model=EllipticEnvelope())]\n",
        "]:\n",
        "    avd.fit(np.hstack([X_train, X_valid]).T)\n",
        "    avd_dict[avd_name] = avd\n",
        "    plt.title(avd_name)\n",
        "    plt.scatter(np.hstack([X_train, X_valid]).T[:, 0], np.hstack([X_train, X_valid]).T[:, 1])\n",
        "    heatmap([avd.transform, avd.transform_bin], axes=[1, -1], drawline=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8cb1wTPjNW8"
      },
      "source": [
        "# SVMによる予測（チューニングなし）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYVxBq3mjKIj"
      },
      "source": [
        "適用範囲を定義する手法を選択します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70B1ziHWjEV7"
      },
      "outputs": [],
      "source": [
        "avd = avd_dict[\"OneClassSVM\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe6qNSnJhizL"
      },
      "source": [
        "予測したい２変数関数を選択します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGK7qNNYyyV-"
      },
      "outputs": [],
      "source": [
        "f = f1\n",
        "Y_train = f(X_train)\n",
        "Y_valid = f(X_valid)\n",
        "Y_test = f(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiRvugdWwtMO"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "model = SVR()\n",
        "model.fit(X_train.T, Y_train)\n",
        "compare_model(f, model.predict, alpha=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PmkcFlOjf4j"
      },
      "source": [
        "# SVMによる予測（チューニングあり）\n",
        "\n",
        "次のようなクラスを作って、SVMをOptunaでハイパーパラメーターチューニングします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCJ-mKIGyYPH"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "class OptunaSVR:\n",
        "    def __init__(self, X_train, X_valid, y_train, y_valid):\n",
        "        self.X_train = X_train\n",
        "        self.X_valid = X_valid\n",
        "        self.y_train = y_train\n",
        "        self.y_valid = y_valid\n",
        "        self.best_score = None\n",
        "        self.best_model = None\n",
        "\n",
        "    def __call__(self, trial):\n",
        "        params = {\n",
        "            \"C\": trial.suggest_float(\"C\", 1e-10, 1e10, log=True),\n",
        "            \"gamma\" : trial.suggest_float(\"gamma\", 1e-10, 1e10, log=True),\n",
        "            \"epsilon\" : trial.suggest_float(\"epsilon\", 1e-10, 1e10, log=True),\n",
        "            \"kernel\" : \"rbf\",\n",
        "            \"max_iter\": 530000,\n",
        "        }\n",
        "        model = SVR(**params)\n",
        "        model.fit(self.X_train, self.y_train)\n",
        "        score = mean_squared_error(model.predict(self.X_valid), self.y_valid)\n",
        "\n",
        "        if self.best_score is None or self.best_score > score:\n",
        "            self.best_score = score\n",
        "            self.best_model = model\n",
        "\n",
        "        return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKnfZAffjw_X"
      },
      "source": [
        "目的変数を次のようにセットします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a5Idy5y26mN"
      },
      "outputs": [],
      "source": [
        "objective = OptunaSVR(X_train.T, X_valid.T, Y_train, Y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HPq54ykj1Yi"
      },
      "source": [
        "次のようにすることで、チューニングの履歴を残すことができます。履歴を残しておくと、中断したチューニングを途中から再開することが可能になります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGJbK6wq3O0M"
      },
      "outputs": [],
      "source": [
        "study_name = \"optuna_svr8\"\n",
        "strage_name = \"optuna_svr8.sql\"\n",
        "study = optuna.create_study(\n",
        "    study_name = study_name,\n",
        "    storage='sqlite:///' + strage_name, \n",
        "    load_if_exists=True,\n",
        "    direction=\"minimize\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euKyG_dukCnC"
      },
      "source": [
        "では、チューニング開始です。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvvqsgBJ3kHx"
      },
      "outputs": [],
      "source": [
        "timeout = 100\n",
        "n_trials = 100\n",
        "show_progress_bar = True\n",
        "study.optimize(\n",
        "    objective, timeout=timeout, n_trials=n_trials, show_progress_bar=show_progress_bar\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjaJUN1ZkL0r"
      },
      "source": [
        "ベストモデルとして選ばれたのはこのモデルです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7KteQAH3tzj"
      },
      "outputs": [],
      "source": [
        "objective.best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkBoH8IIpWTM"
      },
      "source": [
        "ベストモデルによる予測結果を可視化して、適用範囲との関係を見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpGakfB95wRX"
      },
      "outputs": [],
      "source": [
        "compare_model(f, objective.best_model.predict, alpha=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_TSJuMckn-e"
      },
      "source": [
        "チューニングによって改善したかどうかは微妙な気がしますが...（改善どころか改悪する場合もあります）\n",
        "\n",
        "チューニングの履歴は次のように確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yqmnFzr58No"
      },
      "outputs": [],
      "source": [
        "study.trials_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_0sbhYqkx56"
      },
      "source": [
        "Optunaでは、ハイパーパラメーターの重要度を算出するオプションも提供しています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfgAgKH1W5ch"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_param_importances(\n",
        "    study=study,\n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2ngbdUtk9JE"
      },
      "source": [
        "# MLPによる予測（チューニングあり）\n",
        "\n",
        "基本的な方法論は上記で既に述べた通りですが、ケーススタディとしてMLPによる予測もやってみましょう。たとえば次のように最適化クラスを定義します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFIa9iwlWJ6u"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARN)\n",
        "\n",
        "class OptunaMLPRegressor:\n",
        "    def __init__(self, X_train, X_valid, y_train, y_valid):\n",
        "        self.X_train = X_train\n",
        "        self.X_valid = X_valid\n",
        "        self.y_train = y_train\n",
        "        self.y_valid = y_valid\n",
        "        self.best_score = None\n",
        "        self.best_model = None\n",
        "\n",
        "    def __call__(self, trial):\n",
        "        n = trial.suggest_int(\"n\", 3, 10) # 層の深さ\n",
        "        h1 = trial.suggest_int(\"h1\", 2, 128) # 入力層のニューロン数\n",
        "        h2 = trial.suggest_int(\"h2\", 2, 128) # 中間層のニューロン数\n",
        "        h3 = trial.suggest_int(\"h3\", 2, 128) # 出力層のニューロン数\n",
        "        hidden_layer_sizes = []\n",
        "        for h in range(n):\n",
        "            if h == 0:\n",
        "                hidden_layer_sizes.append(h1)\n",
        "            elif h == n - 1:\n",
        "                hidden_layer_sizes.append(h3)\n",
        "            else:\n",
        "                hidden_layer_sizes.append(h2)\n",
        "\n",
        "        learning_rate = trial.suggest_categorical( # 学習率のスケジューリング\n",
        "            \"learning_rate\", [\"constant\", \"invscaling\", \"adaptive\"]\n",
        "        )\n",
        "        learning_rate_init = trial.suggest_float( # 初期の学習率\n",
        "            \"learning_rate_init\", 0.0001, 0.01, log=True\n",
        "        )\n",
        "        activation = trial.suggest_categorical( # 活性化関数\n",
        "            \"activation\", [\"logistic\", \"tanh\", \"relu\"]\n",
        "        )\n",
        "        # バッチサイズ\n",
        "        batch_size = trial.suggest_int(\"batch_size\", 2, self.X_train.shape[0])\n",
        "\n",
        "        params = {\n",
        "                \"max_iter\": 2000, # 計算繰り返し回数の上限\n",
        "                \"random_state\": 0,\n",
        "                \"hidden_layer_sizes\": hidden_layer_sizes,\n",
        "                \"learning_rate\": learning_rate,\n",
        "                \"learning_rate_init\": learning_rate_init,\n",
        "                \"activation\": activation,\n",
        "                \"batch_size\": batch_size,\n",
        "                \"early_stopping\": True,\n",
        "        }\n",
        "        model = MLPRegressor(**params) # 予測モデルの立ち上げ\n",
        "        model.fit(self.X_train, self.y_train) # training data を用いた学習\n",
        "        # validation data を用いたスコア算出\n",
        "        score = mean_squared_error(model.predict(self.X_valid), self.y_valid, squared=False)\n",
        "\n",
        "        # ベストスコアが出たら保存\n",
        "        if self.best_score is None or self.best_score > score:\n",
        "            self.best_score = score\n",
        "            self.best_model = model\n",
        "\n",
        "        return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlg6-z9PrRBx"
      },
      "source": [
        "目的変数を次のようにセットします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgDluujrYncV"
      },
      "outputs": [],
      "source": [
        "objective = OptunaMLPRegressor(X_train.T, X_valid.T, Y_train, Y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-VgiSNTrUNt"
      },
      "source": [
        "次のようにすることで、チューニングの履歴を残すことができます。履歴を残しておくと、中断したチューニングを途中から再開することが可能になります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URUFhvVIYtud"
      },
      "outputs": [],
      "source": [
        "study_name = \"optuna_mlp3\"\n",
        "strage_name = \"optuna_mlp3.sql\"\n",
        "study = optuna.create_study(\n",
        "    study_name = study_name,\n",
        "    storage='sqlite:///' + strage_name, \n",
        "    load_if_exists=True,\n",
        "    direction=\"minimize\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOnDAu2CrZ5x"
      },
      "source": [
        "では、チューニング開始です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMvJcrwhYzO5"
      },
      "outputs": [],
      "source": [
        "timeout = 100\n",
        "n_trials = 100\n",
        "show_progress_bar = True\n",
        "study.optimize(\n",
        "    objective, timeout=timeout, n_trials=n_trials, #show_progress_bar=show_progress_bar\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAHqI8W1t8D1"
      },
      "source": [
        "ベストモデルのパラメーターはこんな感じ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1F-HCIb8Y5Xs"
      },
      "outputs": [],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxtTYlfuA_-"
      },
      "source": [
        "ハイパラチューニングの履歴はこのようになります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrTWuvp4aTFF"
      },
      "outputs": [],
      "source": [
        "study.trials_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D68h2I_uEBl"
      },
      "source": [
        "ハイパラの重要度はこのようになります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoCgypBLaWJn"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_param_importances(\n",
        "    study=study,\n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcQpArFnuJXn"
      },
      "source": [
        "ベストモデルによる予測結果を寿司するとこんな感じ。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vkKPtWbaYM6"
      },
      "outputs": [],
      "source": [
        "compare_model(f, objective.best_model.predict, alpha=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWj-P90xl-JK"
      },
      "source": [
        "# LightGBM\n",
        "\n",
        "最後に、非深層系で最強クラスと噂される LightGBM を使ってみます。Optunaを用いた普通のチューニングも可能なのですが、次のような特別なインテグレーションもOptunaで提供されています（使い方が異なる部分が多いので、慣れないとちょっと辛い）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPJusGZJ-3kP"
      },
      "outputs": [],
      "source": [
        "import optuna.integration.lightgbm as lgb\n",
        "\n",
        "lgb_train = lgb.Dataset(X_train.T, Y_train)\n",
        "lgb_test = lgb.Dataset(X_valid.T, Y_valid, reference=lgb_train)\n",
        "lgb_results={}\n",
        "class OptunaGBM:\n",
        "    def __init__(self, X_train, X_valid, y_train, y_valid):\n",
        "        self.X_train = X_train\n",
        "        self.X_valid = X_valid\n",
        "        self.y_train = y_train\n",
        "        self.y_valid = y_valid\n",
        "        self.best_score = None\n",
        "        self.best_model = None\n",
        "\n",
        "    def __call__(self, trial):\n",
        "        params = {\n",
        "                'task': 'train',                 \n",
        "                'boosting_type': 'gbdt',         \n",
        "                'objective': 'regression',       \n",
        "                'metric': ['rmse'],             \n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.1, 1.0),  \n",
        "                'num_leaves': trial.suggest_int(\"num_leaves\", 5, 50),\n",
        "                'tree_learner': trial.suggest_categorical('tree_learner', [\"serial\", \"feature\", \"data\", \"voting\"]),\n",
        "                'seed': 530000                     \n",
        "                }\n",
        "        model = lgb.train(\n",
        "                    params=params,                    \n",
        "                    train_set=lgb_train,              \n",
        "                    valid_sets=[lgb_train, lgb_test], \n",
        "                    valid_names=['Train', 'Test'],    \n",
        "                    num_boost_round=100,              \n",
        "                    early_stopping_rounds=50,         \n",
        "                    evals_result=lgb_results,\n",
        "                    #verbose_eval=-1,                 \n",
        "                    )\n",
        "        score = mean_squared_error(model.predict(self.X_valid), self.y_valid, squared=False)\n",
        "\n",
        "        if self.best_score is None or self.best_score > score:\n",
        "            self.best_score = score\n",
        "            self.best_model = model\n",
        "\n",
        "        return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "490jQaPkvLQN"
      },
      "source": [
        "目的変数を次のようにセットします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrSGaDOeCGL7"
      },
      "outputs": [],
      "source": [
        "objective = OptunaGBM(X_train.T, X_valid.T, Y_train, Y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wysqupQbvO49"
      },
      "source": [
        "次のようにすることで、チューニングの履歴を残すことができます。履歴を残しておくと、中断したチューニングを途中から再開することが可能になります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYc7RvCLCnSh"
      },
      "outputs": [],
      "source": [
        "study_name = \"optuna_gbm1\"\n",
        "strage_name = \"optuna_gbm1.sql\"\n",
        "study = optuna.create_study(\n",
        "    study_name = study_name,\n",
        "    storage='sqlite:///' + strage_name, \n",
        "    load_if_exists=True,\n",
        "    direction=\"minimize\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf62cVrgvUQW"
      },
      "source": [
        "では、チューニング開始です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmbKl2v_CupG"
      },
      "outputs": [],
      "source": [
        "timeout = 100\n",
        "n_trials = 100\n",
        "show_progress_bar = True\n",
        "study.optimize(\n",
        "    objective, timeout=timeout, n_trials=n_trials, #show_progress_bar=show_progress_bar\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HsBwKYIvZjP"
      },
      "source": [
        "ベストモデルのパラメーターはこんな感じ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeTfQqHhWSJt"
      },
      "outputs": [],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnAs0swUve7Z"
      },
      "source": [
        "ハイパラチューニングの履歴はこのようになります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py0l3rlmVYyS"
      },
      "outputs": [],
      "source": [
        "study.trials_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_FS9F8Pvipq"
      },
      "source": [
        "ハイパラの重要度はこのようになります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWECH4rIV5da"
      },
      "outputs": [],
      "source": [
        "optuna.visualization.plot_param_importances(\n",
        "    study=study,\n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw4zy8XqvoQw"
      },
      "source": [
        "ベストモデルによる予測結果を寿司するとこんな感じ。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPTuC__cCzyj"
      },
      "outputs": [],
      "source": [
        "compare_model(f, objective.best_model.predict, alpha=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ak1e_W41a-s"
      },
      "source": [
        "# 課題\n",
        "\n",
        "1. 適用範囲を定義するためのさまざまなモデルの「クセ」を簡単に説明してください。\n",
        "2. さまざまな予測モデルの「クセ」を簡単に説明してください。\n",
        "3. 適用範囲の内側と外側に対して、さまざまな予測モデルがどのような挙動を示したか説明してください。\n",
        "4. 関数 f4 に対して同じ計算を行い、関数 f1 による結果と照らし合わせて、共通点や相違点を説明してください。\n",
        "\n",
        "\n",
        "\n",
        "**提出方法**：\n",
        "\n",
        "下記のいずれかの方法で提出してください。\n",
        "\n",
        "- Google Colaboratory 上で動作させたコードを ikemenmaskot@gmail.com に「共有」\n",
        "\n",
        "- Jupyter Notebook 上で動作させたコードを ipynb 形式または html 形式にして ikemenmaskot@gmail.com に「メール送信」\n",
        "\n",
        "\n",
        "# 次回\n",
        "\n",
        "これまで、創薬と全く関係のない機械学習の話をしてきましたが、第３回はいよいよ RDKit というツールを用いて化学構造の演算の説明をしたいと思います。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}